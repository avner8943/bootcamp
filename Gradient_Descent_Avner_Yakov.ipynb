{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Nov 15 21:10:51 2020\n",
        "\n",
        "@author: avner\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "older_sibling = [31, 22, 40, 26]\n",
        "\n",
        "younger_silbing = [22, 21, 37, 25]\n",
        "\n",
        "times_talked = [2,3,8,12]\n",
        "\n",
        "comb = np.column_stack((older_sibling, younger_silbing)) \n",
        "\n",
        "x1, x2 = (np.linalg.inv((comb.T @ comb)) @ comb.T) @ times_talked\n",
        "\n",
        "# add bias feature to hold the possibilty for linear model \n",
        "# not going thru the origin of parameters space\n",
        "\n",
        "comb = np.column_stack((older_sibling, younger_silbing, np.ones((4,1)))) \n",
        "\n",
        "\n",
        "x1, x2, b = (np.linalg.inv((comb.T @ comb)) @ comb.T) @ times_talked\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PNQsyHiB2dE"
      },
      "source": [
        "### Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCkFNwC1B5ZH",
        "outputId": "a415274f-ee1d-4e75-8fca-e5d68eabb199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### part 2\n",
        "\n",
        "def gradient_descent( x, y, epoch, lr,t0=0, t1=0, t2=0):\n",
        "    \n",
        "    n = x.shape[0]\n",
        "    \n",
        "    for i in range(epoch):\n",
        "        \n",
        "        y_pred = t0+ t1*x + t2*(x**2)\n",
        "        \n",
        "        dt0 = (-2/n)* np.sum(y-y_pred)\n",
        "        \n",
        "        dt1 = (-2/n)* np.sum(x*(y-y_pred))\n",
        "        \n",
        "        dt2 = (-2/n)* np.sum(x**2 * (y-y_pred))\n",
        "        \n",
        "        t0 = t0 - lr * dt0\n",
        "        \n",
        "        t1 = t1 - lr * dt1\n",
        "        \n",
        "        t2 = t2 - lr * dt2\n",
        "        \n",
        "    return t0, t1, t2   \n",
        "\n",
        "\n",
        "x = np.array([0,1,2])\n",
        "y = np.array([1,3,7])\n",
        "\n",
        "t0, t1, t2 =  gradient_descent( x, y, epoch = 2, lr=1, t0=2, t1=2, t2=0)\n",
        "\n",
        "loss_lr_1 = (1/x.shape[0])*np.sum((y - (t0+ t1*x + t2*(x**2)))**2)\n",
        "\n",
        "print(\"loss with lr=1\", loss_lr_1)\n",
        "\n",
        "t0, t1, t2 =  gradient_descent( x, y, epoch = 2, lr=0.1, t0=2, t1=2, t2=0)\n",
        "\n",
        "loss_lr_0_1 = (1/x.shape[0])*np.sum((y - (t0+ t1*x + t2*(x**2)))**2)\n",
        "\n",
        "print(\"loss with lr=0.1\", loss_lr_0_1)\n",
        "        \n",
        "\n",
        "def gradient_descent_momentum( x, y, epoch, lr,t0=0, t1=0, t2=0):\n",
        "    \n",
        "    gamma = 0.9\n",
        "    n = x.shape[0]\n",
        "    vel = np.array([0]*3)\n",
        "    \n",
        "    for i in range(epoch):\n",
        "        \n",
        "        y_pred = t0+ t1*x + t2*(x**2)\n",
        "        \n",
        "        dt0 = (-2/n)* np.sum(y-y_pred)\n",
        "        \n",
        "        dt1 = (-2/n)* np.sum(x*(y-y_pred))\n",
        "        \n",
        "        dt2 = (-2/n)* np.sum(x**2 * (y-y_pred))\n",
        "\n",
        "        vel[0] = gamma * vel[0]+ lr*dt0\n",
        "        t0 -= vel[0]\n",
        "        \n",
        "        vel[1] = gamma * vel[1]+ lr*dt1\n",
        "        t1 -= vel[1]\n",
        "        \n",
        "        vel[2] = gamma * vel[2]+ lr*dt2\n",
        "        t2 -= vel[2]\n",
        "        \n",
        "    return t0, t1, t2   \n",
        "\n",
        "loss_lr_0_1_m = (1/x.shape[0])*np.sum((y - (t0+ t1*x + t2*(x**2)))**2)\n",
        "\n",
        "print(\"loss with lr=0.1 and momentum\", loss_lr_0_1_m)\n",
        "        "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss with lr=1 4846.893004115225\n",
            "loss with lr=0.1 0.6284115226337451\n",
            "loss with lr=0.1 and momentum 0.6284115226337451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrhzAETrB_Fl"
      },
      "source": [
        "### add momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kIE7mAeCC0U",
        "outputId": "46ca8d30-0a07-4ebb-f19e-c0ed9f48ac43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def gradient_descent_momentum( x, y, epoch, lr,t0=0, t1=0, t2=0):\n",
        "    \n",
        "    gamma = 0.9\n",
        "    n = x.shape[0]\n",
        "    vel = np.array([0]*3)\n",
        "    \n",
        "    for i in range(epoch):\n",
        "        \n",
        "        y_pred = t0+ t1*x + t2*(x**2)\n",
        "        \n",
        "        dt0 = (-2/n)* np.sum(y-y_pred)\n",
        "        \n",
        "        dt1 = (-2/n)* np.sum(x*(y-y_pred))\n",
        "        \n",
        "        dt2 = (-2/n)* np.sum(x**2 * (y-y_pred))\n",
        "\n",
        "        vel[0] = gamma * vel[0]+ lr*dt0\n",
        "        t0 -= vel[0]\n",
        "        \n",
        "        vel[1] = gamma * vel[1]+ lr*dt1\n",
        "        t1 -= vel[1]\n",
        "        \n",
        "        vel[2] = gamma * vel[2]+ lr*dt2\n",
        "        t2 -= vel[2]\n",
        "        \n",
        "    return t0, t1, t2   \n",
        "\n",
        "loss_lr_0_1_m = (1/x.shape[0])*np.sum((y - (t0+ t1*x + t2*(x**2)))**2)\n",
        "\n",
        "print(\"loss with lr=0.1 and momentum\", loss_lr_0_1_m)\n",
        "        "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss with lr=0.1 and momentum 0.6284115226337451\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}